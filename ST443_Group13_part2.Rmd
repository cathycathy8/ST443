---
output:
  word_document: default
  pdf_document: default
---

**ST443 Group13 project part2**
The project is to apply coordinate descent type of algorithm on penalized regression problems,e.g. the lasso in (1) and elastic net in (2).
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Algorithm 1 Coordinate Descent Algorithm for Solving the Lasso
<!--lasso limitation in three scenarios-->
```{r, echo=FALSE}

```

2.Coordinate Descent Algorithm for Solving the Elastic net with regularization
<!--selection of regularization parameters-->
```{r, echo=FALSE}

```

3.Data simulation and numerical results
<!--The simulation is to show that the elastic net not only dominates the lasso in terms of prediction accuracy, but also do a good job in variable selection

To possibly obtain a higher mark, you can also try other simulation settings (e.g.different values of n, p, σ, sparsity level of β and etc.) to demonstrate the superiority of elastic net over the lasso in many scenarios.-->
```{r, echo=FALSE}

```

4. Summary and findings

```{r, echo=FALSE}


# Function to simulate data
simulate_data <- function(n, p, sigma, beta_true, correlation_matrix) {
  set.seed(123)
  X <- matrix(rnorm(n * p), nrow = n)
  X <- scale(X)
  
  # Generate correlated predictors
  for (j in 2:p) {
    X[, j] <- X[, j] + correlation_matrix[1:(j-1), j] %*% X[, 1:(j-1)]
  }
  
  epsilon <- rnorm(n, mean = 0, sd = sigma)
  y <- X %*% beta_true + epsilon
  
  return(list(X = X, y = y))
}
```

